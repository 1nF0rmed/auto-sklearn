{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Resampling Strategies\n\nIn *auto-sklearn* it is possible to use different resampling strategies\nby specifying the arguments ``resampling_strategy`` and\n``resampling_strategy_arguments``. The following example shows common\nsettings for the ``AutoSklearnClassifier``.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport sklearn.model_selection\nimport sklearn.datasets\nimport sklearn.metrics\n\nimport autosklearn.classification\n\n\nif __name__ == \"__main__\":\n    ############################################################################\n    # Data Loading\n    # ============\n\n    X, y = sklearn.datasets.load_breast_cancer(return_X_y=True)\n    X_train, X_test, y_train, y_test = \\\n        sklearn.model_selection.train_test_split(X, y, random_state=1)\n\n    ############################################################################\n    # Holdout\n    # =======\n\n    automl = autosklearn.classification.AutoSklearnClassifier(\n        time_left_for_this_task=120,\n        per_run_time_limit=30,\n        tmp_folder='/tmp/autosklearn_resampling_example_tmp',\n        output_folder='/tmp/autosklearn_resampling_example_out',\n        disable_evaluator_output=False,\n        # 'holdout' with 'train_size'=0.67 is the default argument setting\n        # for AutoSklearnClassifier. It is explicitly specified in this example\n        # for demonstrational purpose.\n        resampling_strategy='holdout',\n        resampling_strategy_arguments={'train_size': 0.67},\n    )\n    automl.fit(X_train, y_train, dataset_name='breast_cancer')\n\n    ############################################################################\n    # Get the Score of the final ensemble\n    # ===================================\n\n    predictions = automl.predict(X_test)\n    print(\"Accuracy score holdout: \", sklearn.metrics.accuracy_score(y_test, predictions))\n\n\n    ############################################################################\n    # Cross-validation\n    # ================\n\n    automl = autosklearn.classification.AutoSklearnClassifier(\n        time_left_for_this_task=120,\n        per_run_time_limit=30,\n        tmp_folder='/tmp/autosklearn_resampling_example_tmp',\n        output_folder='/tmp/autosklearn_resampling_example_out',\n        disable_evaluator_output=False,\n        resampling_strategy='cv',\n        resampling_strategy_arguments={'folds': 5},\n    )\n    automl.fit(X_train, y_train, dataset_name='breast_cancer')\n\n    # One can use models trained during cross-validation directly to predict\n    # for unseen data. For this, all k models trained during k-fold\n    # cross-validation are considered as a single soft-voting ensemble inside\n    # the ensemble constructed with ensemble selection.\n    print('Before re-fit')\n    predictions = automl.predict(X_test)\n    print(\"Accuracy score CV\", sklearn.metrics.accuracy_score(y_test, predictions))\n\n    ############################################################################\n    # Perform a refit\n    # ===============\n    # During fit(), models are fit on individual cross-validation folds. To use\n    # all available data, we call refit() which trains all models in the\n    # final ensemble on the whole dataset.\n    print('After re-fit')\n    automl.refit(X_train.copy(), y_train.copy())\n    predictions = automl.predict(X_test)\n    print(\"Accuracy score CV\", sklearn.metrics.accuracy_score(y_test, predictions))\n\n    ############################################################################\n    # scikit-learn splitter objects\n    # =============================\n    # It is also possible to use\n    # `scikit-learn's splitter classes <https://scikit-learn.org/stable/modules/classes.html#splitter\n    # -classes>`_ to further customize the outputs. In case one needs to have 100% control over the\n    # splitting, it is possible to use\n    # `scikit-learn's PredefinedSplit <https://scikit-learn.org/stable/modules/generated/\n    # sklearn.model_selection.PredefinedSplit.html>`_.\n\n    ############################################################################\n    # Below is an example of using a predefined split. We split the training\n    # data by the first feature. In practice, one would use a splitting according\n    # to the use case at hand.\n\n    resampling_strategy = sklearn.model_selection.PredefinedSplit\n    resampling_strategy_arguments = {'test_fold': np.where(X_train[:, 0] < np.mean(X_train[:, 0]))[0]}\n\n    automl = autosklearn.classification.AutoSklearnClassifier(\n        time_left_for_this_task=120,\n        per_run_time_limit=30,\n        tmp_folder='/tmp/autosklearn_resampling_example_tmp',\n        output_folder='/tmp/autosklearn_resampling_example_out',\n        disable_evaluator_output=False,\n        resampling_strategy=resampling_strategy,\n        resampling_strategy_arguments=resampling_strategy_arguments,\n    )\n    automl.fit(X_train, y_train, dataset_name='breast_cancer')\n\n    ############################################################################\n    # For custom resampling strategies (i.e. resampling strategies that are not\n    # defined as strings by Auto-sklearn) it is necessary to perform a refit:\n    automl.refit(X_train, y_train)\n\n    ############################################################################\n    # Get the Score of the final ensemble (again)\n    # ===========================================\n    #\n    # Obviously, this score is pretty bad as we \"destroyed\" the dataset by\n    # splitting it on the first feature.\n    predictions = automl.predict(X_test)\n    print(\"Accuracy score custom split\", sklearn.metrics.accuracy_score(y_test, predictions))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}